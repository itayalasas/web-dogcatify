# Sistema de Alertas Autom√°ticas DogCatify

## Descripci√≥n General

Sistema completo de monitoreo y alertas que detecta anomal√≠as en la aplicaci√≥n y env√≠a notificaciones por email autom√°ticamente cuando se superan umbrales configurables.

## Caracter√≠sticas

‚úÖ **Monitoreo en tiempo real** de errores en audit_logs
‚úÖ **5 tipos de alertas predefinidas** configurables
‚úÖ **Umbrales personalizables** para cada tipo de alerta
‚úÖ **Cooldown inteligente** para evitar spam de notificaciones
‚úÖ **Emails autom√°ticos** con detalles de la anomal√≠a
‚úÖ **Panel de configuraci√≥n** en el dashboard de administrador
‚úÖ **Pruebas manuales** de alertas desde el panel

## Tipos de Alertas Disponibles

### 1. Errores de Pago (CRITICAL)
- **Umbral por defecto**: 5 errores en 10 minutos
- **Patr√≥n**: payment
- **Cooldown**: 30 minutos
- Detecta problemas con Mercado Pago, links de pago, etc.

### 2. Errores de Base de Datos (CRITICAL)
- **Umbral por defecto**: 5 errores en 5 minutos
- **Patr√≥n**: database|connection|timeout
- **Cooldown**: 30 minutos
- Detecta problemas de conexi√≥n, timeouts, queries fallidos

### 3. Fallos de Autenticaci√≥n (HIGH)
- **Umbral por defecto**: 10 errores en 15 minutos
- **Patr√≥n**: login|auth
- **Cooldown**: 60 minutos
- Detecta intentos de login fallidos, problemas de sesi√≥n

### 4. Errores de API - 5xx (HIGH)
- **Umbral por defecto**: 8 errores en 10 minutos
- **Patr√≥n**: 5xx|500|502|503
- **Cooldown**: 30 minutos
- Detecta errores del servidor, APIs ca√≠das

### 5. Actividad Sospechosa (MEDIUM)
- **Umbral por defecto**: 15 errores en 30 minutos
- **Cooldown**: 120 minutos
- Detecta patrones anormales generales

## Configuraci√≥n

### Acceso al Panel

1. Ir a **Dashboard Admin** ‚Üí **Seguridad** ‚Üí **Alertas**
2. Ver√°s todas las alertas configuradas con sus par√°metros

### Par√°metros Configurables

Para cada tipo de alerta puedes ajustar:

- **Habilitado/Deshabilitado**: Toggle on/off
- **Umbral de errores**: N√∫mero de errores necesarios para disparar la alerta
- **Ventana de tiempo**: Minutos en los que se cuentan los errores (1-120 min)
- **Cooldown**: Tiempo m√≠nimo entre alertas del mismo tipo (5-480 min)
- **Email de notificaci√≥n**: Destinatario de las alertas

### Ejemplo de Configuraci√≥n

```
Alerta: Errores de Pago
- Umbral: 5 errores
- Ventana: 10 minutos
- Cooldown: 30 minutos
- Email: admin@dogcatify.com

Significado: Si hay 5+ errores relacionados con pagos en 10 minutos,
enviar email a admin@dogcatify.com. No enviar otra alerta del mismo
tipo hasta que pasen 30 minutos.
```

## Email de Alerta

Cuando se dispara una alerta, se env√≠a un email con el template `admin_system_anomaly_alert` que incluye:

### Informaci√≥n de la Alerta
- **ID de Alerta**: ALT-YYYYMMDD-XXXXX
- **Severidad**: LOW | MEDIUM | HIGH | CRITICAL
- **Tipo de Anomal√≠a**: Nombre descriptivo
- **Fecha/Hora de Detecci√≥n**: Con timezone -03
- **Duraci√≥n**: Tiempo de la ventana de monitoreo
- **Estado**: DETECTADO | EN INVESTIGACI√ìN

### M√©tricas y Detalles
- **Resumen**: Descripci√≥n de qu√© se detect√≥
- **Impacto**: Usuarios afectados y consecuencias
- **M√©tricas clave**: Conteo de errores, tasa, latencia
- **Causa sospechada**: Primer mensaje de error capturado
- **Correlation ID**: Para rastrear en logs

### Links √ötiles
- **Runbook URL**: Documentaci√≥n de procedimientos
- **Dashboard URL**: Link directo al panel de seguridad
- **Logs URL**: Link a los logs de auditor√≠a
- **Acci√≥n requerida**: Pasos recomendados
- **Asignado a**: Equipo responsable

### Ejemplo de JSON Enviado

```json
{
  "template_name": "admin_system_anomaly_alert",
  "recipient_email": "admin@dogcatify.com",
  "subject": "üö® [ALERTA CRITICAL] Errores de Pago | DogCatiFy",
  "alert_id": "ALT-20260207-00087",
  "wait_for_invoice": false,
  "data": {
    "environment": "PROD",
    "severity": "CRITICAL",
    "service": "payment-errors",
    "anomaly_type": "Errores de Pago",
    "detected_at": "07/02/2026 22:41 (-03)",
    "duration": "10 min",
    "status": "DETECTADO",
    "summary": "Se detectaron 8 errores de tipo 'Errores de Pago' en los √∫ltimos 10 minutos. Umbral configurado: 5 errores.",
    "impact": "3 usuarios afectados. Posible degradaci√≥n del servicio.",
    "key_metrics": "Errores: 8 | Ventana: 10min | Umbral: 5",
    "suspected_cause": "Error connecting to Mercado Pago API",
    "correlation_id": "corr-alt-20260207-00087",
    "reference": "ALT-20260207-00087",
    "runbook_url": "https://dogcatify.com/runbooks/payment_errors",
    "dashboard_url": "https://dogcatify.com/admin/seguridad",
    "logs_url": "https://dogcatify.com/admin/seguridad?tab=logs",
    "action_required": "Revisar logs de auditor√≠a y determinar causa ra√≠z. Escalar si persiste m√°s de 30 minutos.",
    "assigned_to": "Admin DogCatify",
    "support_email": "soporte@dogcatify.com",
    "year": "2026"
  }
}
```

## Monitoreo Autom√°tico

### Edge Function: check-alert-thresholds

Se ha desplegado una funci√≥n edge que verifica todos los umbrales:

**URL**: `{SUPABASE_URL}/functions/v1/check-alert-thresholds`

Esta funci√≥n:
1. Lee la configuraci√≥n de alertas desde admin_settings
2. Para cada alerta habilitada:
   - Verifica si est√° en cooldown
   - Cuenta errores en audit_logs seg√∫n el patr√≥n y ventana de tiempo
   - Si supera el umbral, env√≠a email de alerta
   - Registra la alerta enviada para respetar el cooldown

### Ejecuci√≥n Autom√°tica (Recomendado)

Para que las alertas se revisen autom√°ticamente, se recomienda configurar un cron job o webhook que llame a la funci√≥n peri√≥dicamente:

#### Opci√≥n 1: Cron Job en Supabase

```sql
-- Crear extensi√≥n pg_cron si no existe
CREATE EXTENSION IF NOT EXISTS pg_cron;

-- Ejecutar cada 5 minutos
SELECT cron.schedule(
  'check-alert-thresholds',
  '*/5 * * * *',
  $$
  SELECT
    net.http_post(
      url:='YOUR_SUPABASE_URL/functions/v1/check-alert-thresholds',
      headers:='{"Content-Type": "application/json", "Authorization": "Bearer YOUR_SERVICE_ROLE_KEY"}'::jsonb,
      body:='{}'::jsonb
    ) as request_id;
  $$
);
```

#### Opci√≥n 2: Servicio Externo (cron-job.org, etc.)

Configurar un cron externo que haga POST a:
```
POST {SUPABASE_URL}/functions/v1/check-alert-thresholds
Headers:
  Authorization: Bearer {SERVICE_ROLE_KEY}
  Content-Type: application/json
```

### Ejecuci√≥n Manual

Desde el panel de Alertas, puedes hacer clic en **"Probar Alerta"** para:
- Verificar si el umbral actual disparar√≠a una alerta
- Enviar un email de prueba si se supera el umbral
- Ver si la alerta est√° en cooldown

## Integraci√≥n con Audit Logs

El sistema funciona analizando la tabla `audit_logs`:

```sql
SELECT COUNT(*) FROM audit_logs
WHERE success = false
  AND created_at >= NOW() - INTERVAL '10 minutes'
  AND (
    error_message ILIKE '%payment%' OR
    action ILIKE '%payment%' OR
    resource_type ILIKE '%payment%'
  );
```

**IMPORTANTE**: Para que las alertas funcionen, debes:
1. Tener la tabla `audit_logs` creada (ver CREATE_AUDIT_LOGS_TABLE.sql)
2. Registrar errores usando `logError()` o `auditService.log()` con `success: false`

## Buenas Pr√°cticas

### 1. Ajustar Umbrales Gradualmente

Empieza con umbrales conservadores y aj√∫stalos seg√∫n:
- Volumen de tr√°fico real
- Tasa de errores normal de tu aplicaci√≥n
- Falsos positivos recibidos

### 2. Configurar Cooldowns Apropiados

- **Alertas cr√≠ticas**: 15-30 minutos
- **Alertas importantes**: 30-60 minutos
- **Alertas informativas**: 60-120 minutos

Evita cooldowns muy cortos que generen spam.

### 3. Usar Diferentes Emails Seg√∫n Severidad

```
CRITICAL ‚Üí oncall@dogcatify.com (alertas inmediatas)
HIGH ‚Üí admin@dogcatify.com (seguimiento r√°pido)
MEDIUM ‚Üí reports@dogcatify.com (revisi√≥n diaria)
```

### 4. Revisar Alertas Peri√≥dicamente

- Verifica que las alertas se env√≠an correctamente
- Revisa los logs de "ALERT_SENT" y "ALERT_FAILED" en audit_logs
- Ajusta patrones si hay muchos falsos positivos

### 5. Documentar Runbooks

Crea documentaci√≥n de procedimientos para cada tipo de alerta:
- Pasos de diagn√≥stico
- Acciones de mitigaci√≥n
- Contactos de escalaci√≥n

## Troubleshooting

### Las alertas no se env√≠an

**Verificar**:
1. ¬øLa tabla audit_logs existe y tiene datos?
2. ¬øHay errores con `success = false` en el rango de tiempo?
3. ¬øLa alerta est√° habilitada en la configuraci√≥n?
4. ¬øEst√° en periodo de cooldown?
5. ¬øEl email de destino es v√°lido?
6. ¬øLa funci√≥n send-email est√° funcionando?

**Logs**: Revisar `audit_logs` buscando `action = 'ALERT_FAILED'`

### Demasiadas alertas (spam)

**Soluciones**:
1. Aumentar el umbral de errores
2. Aumentar el cooldown
3. Refinar el patr√≥n de error para ser m√°s espec√≠fico
4. Considerar deshabilitar temporalmente

### Email no llega

**Verificar**:
1. Template `admin_system_anomaly_alert` existe en send-email
2. Credenciales de email est√°n configuradas
3. Email no est√° en spam
4. Verificar logs de la funci√≥n send-email

## Monitoreo del Sistema de Alertas

El sistema se auto-monitorea:
- Cada alerta enviada crea un log con `action = 'ALERT_SENT'`
- Cada fallo crea un log con `action = 'ALERT_FAILED'`
- Puedes crear una meta-alerta para monitorear `ALERT_FAILED` üòÑ

## Pr√≥ximas Mejoras

- [ ] Dashboard de m√©tricas de alertas
- [ ] Integraci√≥n con Slack/Discord
- [ ] Alertas basadas en tendencias (no solo umbrales)
- [ ] Machine Learning para detectar anomal√≠as
- [ ] Agregaci√≥n de alertas similares
- [ ] Resoluci√≥n autom√°tica de alertas

## Soporte

Para m√°s informaci√≥n:
- C√≥digo: `src/services/alerts.service.ts`
- Componente: `src/components/admin/SecurityManager.tsx` (pesta√±a Alertas)
- Edge Function: `supabase/functions/check-alert-thresholds/index.ts`
- Audit System: `SISTEMA_AUDITORIA.md`
